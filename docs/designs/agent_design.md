# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆæ›¸: éMCPåŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©³ç´°è¨­è¨ˆ

**æ³¨**: æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ä½¿ç”¨ã•ã‚Œã‚‹æŠ€è¡“ç”¨èªãƒ»ç•¥èªã®å®šç¾©ã¯[ç”¨èªé›†](../others/glossary.md)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

---

## 1. æ¦‚è¦

### 1.1 ç›®çš„

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€MLOpsã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦**MCPåŒ–ã•ã‚Œã¦ã„ãªã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**ã®è©³ç´°è¨­è¨ˆã‚’å®šç¾©ã—ã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§11å€‹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå­˜åœ¨ã—ã€ãã®ã†ã¡10å€‹ã¯MCPçµ±åˆã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ãŒã€**Judge Agent**ã®ã¿ãŒAWS Lambdaå˜ä½“ã§å®Ÿè£…ã•ã‚Œã¾ã™ã€‚

### 1.2 å¯¾è±¡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

| ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå | MCPåŒ– | å®Ÿè£…æ–¹æ³• | ç†ç”± |
| -------------- | ----- | -------- | ---- |
| Judge Agent    | âŒ    | AWS Lambda | è»½é‡ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯åˆ¤å®šã®ãŸã‚ã€MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã¯ä¸è¦ |

### 1.3 Judge Agentã®å½¹å‰²

Judge Agentã¯ã€MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ãŠã„ã¦**è©•ä¾¡çµæœã®åˆ¤å®šã¨æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š**ã‚’æ‹…å½“ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ä»¥ä¸‹ã®è²¬å‹™ã‚’æŒã¡ã¾ã™ï¼š

- **è©•ä¾¡çµæœã®åˆ¤å®š**: Evaluation Agentã®å‡ºåŠ›ï¼ˆç²¾åº¦ã€æå¤±ç­‰ï¼‰ã‚’é–¾å€¤ã¨æ¯”è¼ƒ
- **åˆæ ¼/ä¸åˆæ ¼ã®æ±ºå®š**: ãƒ¢ãƒ‡ãƒ«ãŒæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã«é©ã—ã¦ã„ã‚‹ã‹åˆ¤å®š
- **æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š**:
  - åˆæ ¼ â†’ Packaging & Deployment ãƒ•ã‚§ãƒ¼ã‚ºã¸é€²ã‚€
  - ä¸åˆæ ¼ â†’ ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã«é€šçŸ¥ & å†å­¦ç¿’ã‚’ææ¡ˆ
- **å¯¾è©±å‹èª¿æ•´ã®åˆ¶å¾¡**: å†å­¦ç¿’ãŒå¿…è¦ãªå ´åˆã€ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¦æ±‚

---

## 2. Judge Agent è©³ç´°è¨­è¨ˆ

### 2.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph "Step Functions Workflow"
        EVAL[Evaluation Agent]
        JUDGE[Judge Agent<br/>AWS Lambda]
        NOTIFY[Notification Agent]
        PACKAGING[Packaging Agent]
    end

    subgraph "External Services"
        SLACK[Slack]
        GITHUB[GitHub Issue]
    end

    EVAL -->|è©•ä¾¡çµæœ| JUDGE
    JUDGE -->|åˆæ ¼| PACKAGING
    JUDGE -->|ä¸åˆæ ¼| NOTIFY
    NOTIFY --> SLACK
    NOTIFY --> GITHUB
```

### 2.2 å…¥åŠ›ãƒ‡ãƒ¼ã‚¿

Judge Agentã¯ã€Step Functionsã‹ã‚‰ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã¾ã™ï¼š

**å…¥åŠ›ã‚¹ã‚­ãƒ¼ãƒ (JSON)**:

```json
{
  "training_id": "train-20250101-001",
  "model_type": "supervised_learning",
  "task_type": "classification",
  "evaluation_results": {
    "accuracy": 0.92,
    "precision": 0.90,
    "recall": 0.94,
    "f1_score": 0.92,
    "auc_roc": 0.95,
    "confusion_matrix_s3_uri": "s3://mlops-bucket/evaluations/train-001/confusion_matrix.png"
  },
  "acceptance_criteria": {
    "min_accuracy": 0.85,
    "min_precision": 0.80,
    "min_recall": 0.80,
    "min_f1_score": 0.80,
    "min_auc_roc": 0.85
  },
  "retry_count": 0,
  "max_retries": 3,
  "github_issue_url": "https://github.com/user/repo/issues/42",
  "notification_channels": ["slack", "github"]
}
```

### 2.3 åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯

#### 2.3.1 åˆæ ¼åˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
def is_model_acceptable(evaluation_results: dict, acceptance_criteria: dict) -> bool:
    """
    ãƒ¢ãƒ‡ãƒ«ãŒæœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ã«é©ã—ã¦ã„ã‚‹ã‹åˆ¤å®š

    Args:
        evaluation_results: è©•ä¾¡çµæœ
        acceptance_criteria: å—å…¥åŸºæº–

    Returns:
        True: åˆæ ¼ï¼ˆãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ï¼‰
        False: ä¸åˆæ ¼ï¼ˆå†å­¦ç¿’å¿…è¦ï¼‰
    """
    criteria_checks = []

    # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸåˆ¤å®š
    if task_type == "classification":
        criteria_checks = [
            evaluation_results.get("accuracy", 0) >= acceptance_criteria.get("min_accuracy", 0.85),
            evaluation_results.get("precision", 0) >= acceptance_criteria.get("min_precision", 0.80),
            evaluation_results.get("recall", 0) >= acceptance_criteria.get("min_recall", 0.80),
            evaluation_results.get("f1_score", 0) >= acceptance_criteria.get("min_f1_score", 0.80),
        ]

        # AUC-ROCãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
        if "auc_roc" in evaluation_results:
            criteria_checks.append(
                evaluation_results["auc_roc"] >= acceptance_criteria.get("min_auc_roc", 0.85)
            )

    elif task_type == "regression":
        criteria_checks = [
            evaluation_results.get("rmse", float('inf')) <= acceptance_criteria.get("max_rmse", 10.0),
            evaluation_results.get("mae", float('inf')) <= acceptance_criteria.get("max_mae", 5.0),
            evaluation_results.get("r2_score", 0) >= acceptance_criteria.get("min_r2_score", 0.80),
        ]

    elif task_type == "clustering":
        criteria_checks = [
            evaluation_results.get("silhouette_score", 0) >= acceptance_criteria.get("min_silhouette_score", 0.50),
        ]

    elif task_type == "reinforcement_learning":
        criteria_checks = [
            evaluation_results.get("avg_reward", 0) >= acceptance_criteria.get("min_avg_reward", 100),
            evaluation_results.get("success_rate", 0) >= acceptance_criteria.get("min_success_rate", 0.70),
        ]

    # ã™ã¹ã¦ã®åŸºæº–ã‚’æº€ãŸã™å ´åˆã®ã¿åˆæ ¼
    return all(criteria_checks)
```

#### 2.3.2 æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯

```python
def determine_next_action(
    is_acceptable: bool,
    retry_count: int,
    max_retries: int
) -> dict:
    """
    æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š

    Returns:
        {
            "action": "deploy" | "retry" | "abort",
            "reason": str,
            "notify_operator": bool
        }
    """
    if is_acceptable:
        return {
            "action": "deploy",
            "reason": "Model meets all acceptance criteria",
            "notify_operator": False
        }

    if retry_count < max_retries:
        return {
            "action": "retry",
            "reason": f"Model does not meet criteria. Retry {retry_count + 1}/{max_retries}",
            "notify_operator": True
        }

    return {
        "action": "abort",
        "reason": f"Model failed after {max_retries} retries. Manual intervention required.",
        "notify_operator": True
    }
```

### 2.4 å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿

**å‡ºåŠ›ã‚¹ã‚­ãƒ¼ãƒ (JSON)**:

```json
{
  "training_id": "train-20250101-001",
  "judgment": {
    "is_acceptable": true,
    "passed_criteria": [
      "accuracy >= 0.85 (actual: 0.92)",
      "precision >= 0.80 (actual: 0.90)",
      "recall >= 0.80 (actual: 0.94)",
      "f1_score >= 0.80 (actual: 0.92)",
      "auc_roc >= 0.85 (actual: 0.95)"
    ],
    "failed_criteria": []
  },
  "next_action": {
    "action": "deploy",
    "reason": "Model meets all acceptance criteria",
    "notify_operator": false
  },
  "retry_count": 0,
  "timestamp": "2025-01-01T12:34:56Z"
}
```

**ä¸åˆæ ¼æ™‚ã®å‡ºåŠ›ä¾‹**:

```json
{
  "training_id": "train-20250101-002",
  "judgment": {
    "is_acceptable": false,
    "passed_criteria": [
      "precision >= 0.80 (actual: 0.82)",
      "recall >= 0.80 (actual: 0.88)"
    ],
    "failed_criteria": [
      "accuracy >= 0.85 (actual: 0.78)",
      "f1_score >= 0.80 (actual: 0.75)",
      "auc_roc >= 0.85 (actual: 0.80)"
    ]
  },
  "next_action": {
    "action": "retry",
    "reason": "Model does not meet criteria. Retry 1/3",
    "notify_operator": true
  },
  "retry_count": 1,
  "timestamp": "2025-01-01T13:00:00Z",
  "operator_notification": {
    "message": "ãƒ¢ãƒ‡ãƒ«ãŒå—å…¥åŸºæº–ã‚’æº€ãŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚ä»¥ä¸‹ã®æ”¹å–„ã‚’æ¤œè¨ã—ã¦ãã ã•ã„:\n\n**å¤±æ•—ã—ãŸåŸºæº–:**\n- accuracy: 0.78 (ç›®æ¨™: 0.85)\n- f1_score: 0.75 (ç›®æ¨™: 0.80)\n- auc_roc: 0.80 (ç›®æ¨™: 0.85)\n\n**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:**\n1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆå­¦ç¿’ç‡ã€æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç­‰ï¼‰\n2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®è¿½åŠ \n3. ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ã®å¼·åŒ–\n\nGitHub Issueã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦èª¿æ•´å†…å®¹ã‚’æŒ‡ç¤ºã—ã¦ãã ã•ã„ã€‚",
    "channels": ["slack", "github"]
  }
}
```

### 2.5 Lambdaé–¢æ•°å®Ÿè£…

#### 2.5.1 Pythonå®Ÿè£…ä¾‹

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `agents/judge_agent/lambda_function.py`

```python
import json
import logging
import os
import re
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger()
logger.setLevel(logging.INFO)


class JudgeAgent:
    """
    è©•ä¾¡çµæœã®åˆ¤å®šã¨æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®šã‚’è¡Œã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """

    def __init__(self):
        self.logger = logger
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ã®èª­ã¿è¾¼ã¿ï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
        self.default_thresholds = self._load_default_thresholds()

    def _load_default_thresholds(self) -> Dict[str, Dict[str, float]]:
        """
        ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ã‚’ç’°å¢ƒå¤‰æ•°ã¾ãŸã¯S3è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿

        ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å€¤ã‚’ä½¿ç”¨
        """
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã®èª­ã¿è¾¼ã¿ï¼ˆJSONå½¢å¼ï¼‰
        thresholds_json = os.getenv("DEFAULT_THRESHOLDS")

        if thresholds_json:
            try:
                return json.loads(thresholds_json)
            except json.JSONDecodeError:
                self.logger.warning("Failed to parse DEFAULT_THRESHOLDS from env, using hardcoded defaults")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å€¤
        return {
            "classification": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80,
                "min_auc_roc": 0.85
            },
            "regression": {
                "max_rmse": 10.0,
                "max_mae": 5.0,
                "min_r2_score": 0.80
            },
            "clustering": {
                "min_silhouette_score": 0.50
            },
            "reinforcement_learning": {
                "min_avg_reward": 100,
                "min_success_rate": 0.70
            }
        }

    def _validate_github_url(self, url: str) -> bool:
        """
        GitHub Issueã®URLæ¤œè¨¼ï¼ˆURLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼‰

        Args:
            url: æ¤œè¨¼ã™ã‚‹URL

        Returns:
            True: æœ‰åŠ¹ãªGitHub Issue URL
            False: ç„¡åŠ¹ãªURL
        """
        if not url:
            return True  # URLãŒç©ºã®å ´åˆã¯æ¤œè¨¼ã‚¹ã‚­ãƒƒãƒ—

        pattern = r'^https://github\.com/[\w-]+/[\w-]+/issues/\d+$'
        return re.match(pattern, url) is not None

    def judge_model(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœã‚’åˆ¤å®šã—ã€æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š

        Args:
            event: Step Functionsã‹ã‚‰ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿

        Returns:
            åˆ¤å®šçµæœã¨æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        """
        training_id = event["training_id"]
        model_type = event["model_type"]
        task_type = event["task_type"]
        evaluation_results = event["evaluation_results"]
        acceptance_criteria = event["acceptance_criteria"]
        retry_count = event.get("retry_count", 0)
        max_retries = event.get("max_retries", 3)

        # GitHub Issue URLæ¤œè¨¼ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ï¼‰
        github_issue_url = event.get("github_issue_url", "")
        if github_issue_url and not self._validate_github_url(github_issue_url):
            raise ValueError(f"Invalid GitHub Issue URL: {github_issue_url}")

        self.logger.info(f"Judging model: {training_id}, task_type: {task_type}")

        # åˆ¤å®šå®Ÿè¡Œ
        is_acceptable, passed_criteria, failed_criteria = self._evaluate_criteria(
            task_type, evaluation_results, acceptance_criteria
        )

        # æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
        next_action = self._determine_next_action(
            is_acceptable, retry_count, max_retries
        )

        # çµæœæ§‹ç¯‰
        result = {
            "training_id": training_id,
            "judgment": {
                "is_acceptable": is_acceptable,
                "passed_criteria": passed_criteria,
                "failed_criteria": failed_criteria
            },
            "next_action": next_action,
            "retry_count": retry_count if not is_acceptable else 0,
            "timestamp": datetime.utcnow().isoformat() + "Z"
        }

        # ã‚ªãƒšãƒ¬ãƒ¼ã‚¿é€šçŸ¥ãŒå¿…è¦ãªå ´åˆ
        if next_action["notify_operator"]:
            result["operator_notification"] = self._create_notification_message(
                training_id, failed_criteria, retry_count, max_retries, event
            )

        self.logger.info(f"Judgment result: {json.dumps(result, indent=2)}")
        return result

    def _evaluate_criteria(
        self,
        task_type: str,
        evaluation_results: Dict[str, float],
        acceptance_criteria: Dict[str, float]
    ) -> tuple[bool, List[str], List[str]]:
        """
        å—å…¥åŸºæº–ã®è©•ä¾¡

        Returns:
            (is_acceptable, passed_criteria, failed_criteria)
        """
        passed = []
        failed = []

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–¾å€¤ã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã¾ãŸã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
        default_thresholds = self.default_thresholds.get(task_type, {})

        if task_type == "classification":
            criteria_map = {
                "accuracy": ("min_accuracy", default_thresholds.get("min_accuracy", 0.85), ">="),
                "precision": ("min_precision", default_thresholds.get("min_precision", 0.80), ">="),
                "recall": ("min_recall", default_thresholds.get("min_recall", 0.80), ">="),
                "f1_score": ("min_f1_score", default_thresholds.get("min_f1_score", 0.80), ">="),
                "auc_roc": ("min_auc_roc", default_thresholds.get("min_auc_roc", 0.85), ">=")
            }
        elif task_type == "regression":
            criteria_map = {
                "rmse": ("max_rmse", default_thresholds.get("max_rmse", 10.0), "<="),
                "mae": ("max_mae", default_thresholds.get("max_mae", 5.0), "<="),
                "r2_score": ("min_r2_score", default_thresholds.get("min_r2_score", 0.80), ">=")
            }
        elif task_type == "clustering":
            criteria_map = {
                "silhouette_score": ("min_silhouette_score", default_thresholds.get("min_silhouette_score", 0.50), ">=")
            }
        elif task_type == "reinforcement_learning":
            criteria_map = {
                "avg_reward": ("min_avg_reward", default_thresholds.get("min_avg_reward", 100), ">="),
                "success_rate": ("min_success_rate", default_thresholds.get("min_success_rate", 0.70), ">=")
            }
        else:
            raise ValueError(f"Unknown task_type: {task_type}")

        for metric_name, (criteria_key, default_threshold, operator) in criteria_map.items():
            if metric_name not in evaluation_results:
                continue

            actual_value = evaluation_results[metric_name]
            threshold = acceptance_criteria.get(criteria_key, default_threshold)

            if operator == ">=":
                is_passed = actual_value >= threshold
            else:  # "<="
                is_passed = actual_value <= threshold

            criterion_text = f"{metric_name} {operator} {threshold} (actual: {actual_value:.4f})"

            if is_passed:
                passed.append(criterion_text)
            else:
                failed.append(criterion_text)

        is_acceptable = len(failed) == 0
        return is_acceptable, passed, failed

    def _determine_next_action(
        self,
        is_acceptable: bool,
        retry_count: int,
        max_retries: int
    ) -> Dict[str, Any]:
        """
        æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®æ±ºå®š
        """
        if is_acceptable:
            return {
                "action": "deploy",
                "reason": "Model meets all acceptance criteria",
                "notify_operator": False
            }

        if retry_count < max_retries:
            return {
                "action": "retry",
                "reason": f"Model does not meet criteria. Retry {retry_count + 1}/{max_retries}",
                "notify_operator": True
            }

        return {
            "action": "abort",
            "reason": f"Model failed after {max_retries} retries. Manual intervention required.",
            "notify_operator": True
        }

    def _create_notification_message(
        self,
        training_id: str,
        failed_criteria: List[str],
        retry_count: int,
        max_retries: int,
        event: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ã‚ªãƒšãƒ¬ãƒ¼ã‚¿å‘ã‘é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆ
        """
        message_lines = [
            f"ğŸš¨ **ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ: ä¸åˆæ ¼**",
            f"",
            f"**Training ID**: `{training_id}`",
            f"**ãƒªãƒˆãƒ©ã‚¤å›æ•°**: {retry_count + 1}/{max_retries}",
            f"",
            f"**å¤±æ•—ã—ãŸåŸºæº–**:"
        ]

        for criterion in failed_criteria:
            message_lines.append(f"- {criterion}")

        message_lines.extend([
            f"",
            f"**æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:",
            f"1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆå­¦ç¿’ç‡ã€æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç­‰ï¼‰",
            f"2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®è¿½åŠ ",
            f"3. ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ã®å¼·åŒ–ï¼ˆSMOTEã€ã‚¯ãƒ©ã‚¹ã‚¦ã‚§ã‚¤ãƒˆèª¿æ•´ç­‰ï¼‰",
            f"4. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¦‹ç›´ã—",
            f"",
            f"GitHub Issueã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦èª¿æ•´å†…å®¹ã‚’æŒ‡ç¤ºã—ã¦ãã ã•ã„:",
            f"{event.get('github_issue_url', 'N/A')}"
        ])

        return {
            "message": "\n".join(message_lines),
            "channels": event.get("notification_channels", ["slack", "github"])
        }


def lambda_handler(event, context):
    """
    Lambdaé–¢æ•°ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
    """
    try:
        judge_agent = JudgeAgent()
        result = judge_agent.judge_model(event)

        return {
            "statusCode": 200,
            "body": result
        }

    except Exception as e:
        logger.error(f"Error in Judge Agent: {str(e)}", exc_info=True)
        return {
            "statusCode": 500,
            "body": {
                "error": str(e),
                "training_id": event.get("training_id", "unknown")
            }
        }
```

#### 2.5.2 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `agents/judge_agent/test_judge_agent.py`

```python
import pytest
from lambda_function import JudgeAgent


class TestJudgeAgent:
    """
    Judge Agentã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
    """

    @pytest.fixture
    def judge_agent(self):
        return JudgeAgent()

    def test_judge_acceptable_classification(self, judge_agent):
        """
        åˆ†é¡ã‚¿ã‚¹ã‚¯ã§åˆæ ¼åˆ¤å®šã®ãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-001",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.92,
                "precision": 0.90,
                "recall": 0.94,
                "f1_score": 0.92,
                "auc_roc": 0.95
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80,
                "min_auc_roc": 0.85
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is True
        assert result["next_action"]["action"] == "deploy"
        assert result["next_action"]["notify_operator"] is False
        assert len(result["judgment"]["failed_criteria"]) == 0

    def test_judge_unacceptable_classification(self, judge_agent):
        """
        åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ä¸åˆæ ¼åˆ¤å®šã®ãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-002",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.78,
                "precision": 0.82,
                "recall": 0.88,
                "f1_score": 0.75,
                "auc_roc": 0.80
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80,
                "min_auc_roc": 0.85
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is False
        assert result["next_action"]["action"] == "retry"
        assert result["next_action"]["notify_operator"] is True
        assert len(result["judgment"]["failed_criteria"]) == 3  # accuracy, f1_score, auc_roc

    def test_judge_max_retries_exceeded(self, judge_agent):
        """
        æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°è¶…éæ™‚ã®ãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-003",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.75,
                "precision": 0.70,
                "recall": 0.80,
                "f1_score": 0.70
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80
            },
            "retry_count": 3,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is False
        assert result["next_action"]["action"] == "abort"
        assert result["next_action"]["notify_operator"] is True

    def test_judge_regression_task(self, judge_agent):
        """
        å›å¸°ã‚¿ã‚¹ã‚¯ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-004",
            "model_type": "supervised_learning",
            "task_type": "regression",
            "evaluation_results": {
                "rmse": 8.5,
                "mae": 4.2,
                "r2_score": 0.88
            },
            "acceptance_criteria": {
                "max_rmse": 10.0,
                "max_mae": 5.0,
                "min_r2_score": 0.80
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is True
        assert result["next_action"]["action"] == "deploy"

    def test_judge_clustering_task(self, judge_agent):
        """
        ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-005",
            "model_type": "unsupervised_learning",
            "task_type": "clustering",
            "evaluation_results": {
                "silhouette_score": 0.65
            },
            "acceptance_criteria": {
                "min_silhouette_score": 0.50
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is True
        assert result["next_action"]["action"] == "deploy"
        assert len(result["judgment"]["passed_criteria"]) == 1

    def test_judge_reinforcement_learning_task(self, judge_agent):
        """
        å¼·åŒ–å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®åˆ¤å®šãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-006",
            "model_type": "reinforcement_learning",
            "task_type": "reinforcement_learning",
            "evaluation_results": {
                "avg_reward": 150.5,
                "success_rate": 0.85
            },
            "acceptance_criteria": {
                "min_avg_reward": 100,
                "min_success_rate": 0.70
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        assert result["judgment"]["is_acceptable"] is True
        assert result["next_action"]["action"] == "deploy"
        assert len(result["judgment"]["passed_criteria"]) == 2

    def test_judge_partial_metrics(self, judge_agent):
        """
        ä¸€éƒ¨ã®æŒ‡æ¨™ã®ã¿å­˜åœ¨ã™ã‚‹å ´åˆã®ãƒ†ã‚¹ãƒˆï¼ˆauc_rocãªã—ï¼‰
        """
        event = {
            "training_id": "train-007",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.90,
                "precision": 0.88,
                "recall": 0.92,
                "f1_score": 0.90
                # auc_roc is missing
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80,
                "min_auc_roc": 0.85
            },
            "retry_count": 0,
            "max_retries": 3
        }

        result = judge_agent.judge_model(event)

        # auc_rocãŒãªãã¦ã‚‚ä»–ã®æŒ‡æ¨™ãŒåˆæ ¼ãªã‚‰å…¨ä½“ã¨ã—ã¦åˆæ ¼
        assert result["judgment"]["is_acceptable"] is True
        assert result["next_action"]["action"] == "deploy"
        assert len(result["judgment"]["passed_criteria"]) == 4

    def test_notification_message_format(self, judge_agent):
        """
        é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-008",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.78,
                "precision": 0.82,
                "recall": 0.88,
                "f1_score": 0.75,
                "auc_roc": 0.80
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85,
                "min_precision": 0.80,
                "min_recall": 0.80,
                "min_f1_score": 0.80,
                "min_auc_roc": 0.85
            },
            "retry_count": 0,
            "max_retries": 3,
            "github_issue_url": "https://github.com/user/repo/issues/42",
            "notification_channels": ["slack", "github"]
        }

        result = judge_agent.judge_model(event)

        # é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å­˜åœ¨ç¢ºèª
        assert "operator_notification" in result
        notification = result["operator_notification"]

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œè¨¼
        assert "message" in notification
        assert "channels" in notification
        assert "ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ: ä¸åˆæ ¼" in notification["message"]
        assert "train-008" in notification["message"]
        assert "accuracy" in notification["message"]
        assert "https://github.com/user/repo/issues/42" in notification["message"]
        assert notification["channels"] == ["slack", "github"]

    def test_github_url_validation_valid(self, judge_agent):
        """
        æœ‰åŠ¹ãªGitHub Issue URLã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
        """
        assert judge_agent._validate_github_url("https://github.com/user/repo/issues/123") is True
        assert judge_agent._validate_github_url("https://github.com/my-org/my-repo/issues/1") is True
        assert judge_agent._validate_github_url("") is True  # ç©ºURLã¯è¨±å¯

    def test_github_url_validation_invalid(self, judge_agent):
        """
        ç„¡åŠ¹ãªGitHub Issue URLã®æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
        """
        # ç„¡åŠ¹ãªURLå½¢å¼
        assert judge_agent._validate_github_url("http://github.com/user/repo/issues/123") is False  # http
        assert judge_agent._validate_github_url("https://github.com/user/repo/pull/123") is False  # pull request
        assert judge_agent._validate_github_url("https://github.com/user/repo") is False  # issueãªã—
        assert judge_agent._validate_github_url("https://evil.com/github.com/user/repo/issues/123") is False  # æ‚ªæ„ã‚ã‚‹URL
        assert judge_agent._validate_github_url("javascript:alert(1)") is False  # XSSæ”»æ’ƒ

    def test_judge_with_invalid_github_url(self, judge_agent):
        """
        ç„¡åŠ¹ãªGitHub Issue URLã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ã®ãƒ†ã‚¹ãƒˆ
        """
        event = {
            "training_id": "train-009",
            "model_type": "supervised_learning",
            "task_type": "classification",
            "evaluation_results": {
                "accuracy": 0.78
            },
            "acceptance_criteria": {
                "min_accuracy": 0.85
            },
            "retry_count": 0,
            "max_retries": 3,
            "github_issue_url": "https://evil.com/malicious"  # ç„¡åŠ¹ãªURL
        }

        with pytest.raises(ValueError) as exc_info:
            judge_agent.judge_model(event)

        assert "Invalid GitHub Issue URL" in str(exc_info.value)
```

### 2.6 Step Functionsçµ±åˆ

Judge Agentã¯Step Functionsã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†…ã§ä»¥ä¸‹ã®ã‚ˆã†ã«ä½¿ç”¨ã•ã‚Œã¾ã™ï¼š

**Step Functionså®šç¾© (ASL - Amazon States Language)**:

```json
{
  "Comment": "MLOps Pipeline - Evaluation & Judgment Phase",
  "StartAt": "EvaluateModel",
  "States": {
    "EvaluateModel": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:EvaluationAgent",
      "ResultPath": "$.evaluation_results",
      "Next": "JudgeModel"
    },
    "JudgeModel": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:JudgeAgent",
      "ResultPath": "$.judgment",
      "Next": "DecideNextAction"
    },
    "DecideNextAction": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.judgment.next_action.action",
          "StringEquals": "deploy",
          "Next": "PackageModel"
        },
        {
          "Variable": "$.judgment.next_action.action",
          "StringEquals": "retry",
          "Next": "NotifyOperator"
        },
        {
          "Variable": "$.judgment.next_action.action",
          "StringEquals": "abort",
          "Next": "AbortWorkflow"
        }
      ],
      "Default": "AbortWorkflow"
    },
    "PackageModel": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:PackagingAgent",
      "End": true
    },
    "NotifyOperator": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:NotificationAgent",
      "Next": "WaitForOperatorAdjustment"
    },
    "WaitForOperatorAdjustment": {
      "Type": "Wait",
      "Seconds": 3600,
      "Next": "CheckAdjustmentProvided"
    },
    "CheckAdjustmentProvided": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:CheckGitHubIssueComment",
      "Next": "HasAdjustment"
    },
    "HasAdjustment": {
      "Type": "Choice",
      "Choices": [
        {
          "Variable": "$.has_adjustment",
          "BooleanEquals": true,
          "Next": "RetrainWithAdjustment"
        }
      ],
      "Default": "AbortWorkflow"
    },
    "RetrainWithAdjustment": {
      "Type": "Task",
      "Resource": "arn:aws:lambda:us-east-1:123456789012:function:TrainingAgent",
      "Next": "EvaluateModel"
    },
    "AbortWorkflow": {
      "Type": "Fail",
      "Error": "ModelRejected",
      "Cause": "Model failed acceptance criteria after maximum retries"
    }
  }
}
```

### 2.7 IAMãƒ­ãƒ¼ãƒ«è¨­è¨ˆ

**Judge Agentç”¨IAMãƒ­ãƒ¼ãƒ«**:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents"
      ],
      "Resource": "arn:aws:logs:*:*:*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject"
      ],
      "Resource": "arn:aws:s3:::mlops-bucket/evaluations/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "cloudwatch:PutMetricData"
      ],
      "Resource": "*",
      "Condition": {
        "StringEquals": {
          "cloudwatch:namespace": "MLOps/JudgeAgent"
        }
      }
    }
  ]
}
```

### 2.8 ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

**CloudWatch Metrics**:

- `JudgmentCount`: åˆ¤å®šå®Ÿè¡Œå›æ•°
- `AcceptanceRate`: åˆæ ¼ç‡ï¼ˆéå»24æ™‚é–“ï¼‰
- `RetryRate`: ãƒªãƒˆãƒ©ã‚¤ç‡
- `AbortRate`: ä¸­æ–­ç‡

**CloudWatch Alarms**:

- `LowAcceptanceRate`: åˆæ ¼ç‡ãŒ50%æœªæº€ã®å ´åˆã«ã‚¢ãƒ©ãƒ¼ãƒˆ
- `HighRetryRate`: ãƒªãƒˆãƒ©ã‚¤ç‡ãŒ70%è¶…ã®å ´åˆã«ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«å“è³ªå•é¡Œã®å¯èƒ½æ€§ï¼‰

---

## 3. å¯¾è©±å‹èª¿æ•´ãƒ•ãƒ­ãƒ¼

### 3.1 å¯¾è©±å‹èª¿æ•´ã®æ¦‚è¦

Judge AgentãŒä¸åˆæ ¼ã¨åˆ¤å®šã—ãŸå ´åˆã€ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã¨ã®å¯¾è©±çš„ãªèª¿æ•´ãƒ—ãƒ­ã‚»ã‚¹ãŒé–‹å§‹ã•ã‚Œã¾ã™ã€‚

```mermaid
sequenceDiagram
    participant SF as Step Functions
    participant JUDGE as Judge Agent
    participant NOTIFY as Notification Agent
    participant OPERATOR as Operator
    participant GITHUB as GitHub Issue
    participant TRAINING as Training Agent

    SF->>JUDGE: è©•ä¾¡çµæœ
    JUDGE->>JUDGE: åˆ¤å®šå®Ÿè¡Œ
    JUDGE-->>SF: ä¸åˆæ ¼ + ãƒªãƒˆãƒ©ã‚¤ææ¡ˆ
    SF->>NOTIFY: ã‚ªãƒšãƒ¬ãƒ¼ã‚¿é€šçŸ¥
    NOTIFY->>GITHUB: Issue ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
    NOTIFY->>OPERATOR: Slacké€šçŸ¥
    OPERATOR->>GITHUB: èª¿æ•´å†…å®¹ã‚³ãƒ¡ãƒ³ãƒˆ
    Note over SF: 1æ™‚é–“å¾…æ©Ÿ
    SF->>GITHUB: ã‚³ãƒ¡ãƒ³ãƒˆç¢ºèª
    alt èª¿æ•´ã‚ã‚Š
        GITHUB-->>SF: èª¿æ•´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        SF->>TRAINING: å†å­¦ç¿’å®Ÿè¡Œ
        TRAINING-->>SF: å­¦ç¿’å®Œäº†
        SF->>JUDGE: å†è©•ä¾¡
    else èª¿æ•´ãªã—
        SF->>SF: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸­æ–­
    end
```

### 3.2 GitHub Issue ã‚³ãƒ¡ãƒ³ãƒˆä¾‹

**Judge Agentã‹ã‚‰ã®é€šçŸ¥**:

```markdown
## ğŸš¨ ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ: ä¸åˆæ ¼

**Training ID**: `train-20250101-002`
**ãƒªãƒˆãƒ©ã‚¤å›æ•°**: 1/3

### å¤±æ•—ã—ãŸåŸºæº–
- accuracy >= 0.85 (actual: 0.7800)
- f1_score >= 0.80 (actual: 0.7500)
- auc_roc >= 0.85 (actual: 0.8000)

### æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ï¼ˆå­¦ç¿’ç‡ã€æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç­‰ï¼‰
2. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®è¿½åŠ 
3. ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾ç­–ã®å¼·åŒ–ï¼ˆSMOTEã€ã‚¯ãƒ©ã‚¹ã‚¦ã‚§ã‚¤ãƒˆèª¿æ•´ç­‰ï¼‰
4. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¦‹ç›´ã—

### èª¿æ•´æ–¹æ³•
ä»¥ä¸‹ã®å½¢å¼ã§ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„ï¼š

\`\`\`yaml
adjust:
  hyperparameters:
    learning_rate: 0.001
    batch_size: 64
    epochs: 150
  preprocessing:
    class_imbalance_method: smote
    smote_ratio: 0.8
\`\`\`
```

**ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ã‹ã‚‰ã®èª¿æ•´ã‚³ãƒ¡ãƒ³ãƒˆä¾‹**:

```yaml
adjust:
  hyperparameters:
    learning_rate: 0.001
    batch_size: 64
    epochs: 150
    weight_decay: 0.0001
  preprocessing:
    class_imbalance_method: smote
    smote_ratio: 0.8
  data_augmentation:
    enabled: true
    mixup_alpha: 0.2
```

---

## 4. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 4.1 CDKã«ã‚ˆã‚‹ãƒ‡ãƒ—ãƒ­ã‚¤å®šç¾©

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `cdk/stacks/judge_agent_stack.py`

```python
from aws_cdk import (
    Stack,
    aws_lambda as lambda_,
    aws_iam as iam,
    aws_logs as logs,
    Duration
)
from constructs import Construct


class JudgeAgentStack(Stack):
    """
    Judge Agentç”¨ã®CDKã‚¹ã‚¿ãƒƒã‚¯
    """

    def __init__(self, scope: Construct, construct_id: str, **kwargs):
        super().__init__(scope, construct_id, **kwargs)

        # IAMãƒ­ãƒ¼ãƒ«
        judge_agent_role = iam.Role(
            self, "JudgeAgentRole",
            assumed_by=iam.ServicePrincipal("lambda.amazonaws.com"),
            managed_policies=[
                iam.ManagedPolicy.from_aws_managed_policy_name(
                    "service-role/AWSLambdaBasicExecutionRole"
                )
            ]
        )

        # S3èª­ã¿å–ã‚Šæ¨©é™
        judge_agent_role.add_to_policy(
            iam.PolicyStatement(
                actions=["s3:GetObject"],
                resources=["arn:aws:s3:::mlops-bucket/evaluations/*"]
            )
        )

        # CloudWatch Metricsæ›¸ãè¾¼ã¿æ¨©é™
        judge_agent_role.add_to_policy(
            iam.PolicyStatement(
                actions=["cloudwatch:PutMetricData"],
                resources=["*"],
                conditions={
                    "StringEquals": {
                        "cloudwatch:namespace": "MLOps/JudgeAgent"
                    }
                }
            )
        )

        # Lambdaé–¢æ•°
        self.judge_agent_function = lambda_.Function(
            self, "JudgeAgentFunction",
            runtime=lambda_.Runtime.PYTHON_3_11,
            handler="lambda_function.lambda_handler",
            code=lambda_.Code.from_asset("../agents/judge_agent"),
            role=judge_agent_role,
            timeout=Duration.seconds(60),
            memory_size=256,
            environment={
                "LOG_LEVEL": "INFO"
            },
            log_retention=logs.RetentionDays.ONE_MONTH
        )
```

### 4.2 ãƒ‡ãƒ—ãƒ­ã‚¤ã‚³ãƒãƒ³ãƒ‰

```bash
cd cdk
cdk deploy JudgeAgentStack
```

---

## 5. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 5.1 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

- **å¯¾è±¡**: åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã€æ¬¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®šãƒ­ã‚¸ãƒƒã‚¯
- **ãƒ„ãƒ¼ãƒ«**: pytest
- **ã‚«ãƒãƒ¬ãƒƒã‚¸ç›®æ¨™**: 90%ä»¥ä¸Š

### 5.2 çµ±åˆãƒ†ã‚¹ãƒˆ

- **å¯¾è±¡**: Step Functionsé€£æºã€Notification Agenté€£æº
- **ãƒ„ãƒ¼ãƒ«**: motoï¼ˆAWSã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ãƒƒã‚¯ï¼‰ã€pytest

### 5.3 E2Eãƒ†ã‚¹ãƒˆ

- **å¯¾è±¡**: GitHub Issue â†’ Judge Agent â†’ å†å­¦ç¿’ã®ä¸€é€£ã®ãƒ•ãƒ­ãƒ¼
- **ç’°å¢ƒ**: ãƒ†ã‚¹ãƒˆç’°å¢ƒï¼ˆdevç’°å¢ƒï¼‰

---

## 6. é‹ç”¨è€ƒæ…®äº‹é …

### 6.1 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

- Lambdaé–¢æ•°å†…ã§ä¾‹å¤–ç™ºç”Ÿæ™‚ã¯Step Functionsã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”å´
- Step Functionsã®Retry/Catchãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

### 6.2 ãƒ­ã‚°ç®¡ç†

- ã™ã¹ã¦ã®åˆ¤å®šçµæœã‚’CloudWatch Logsã«è¨˜éŒ²
- æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆJSONå½¢å¼ï¼‰ã§æ¤œç´¢å®¹æ˜“æ€§ã‚’ç¢ºä¿

### 6.3 ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–

- åˆæ ¼ç‡ã€ãƒªãƒˆãƒ©ã‚¤ç‡ã€ä¸­æ–­ç‡ã‚’CloudWatch Metricsã§è¿½è·¡
- ç•°å¸¸å€¤æ¤œçŸ¥æ™‚ã¯SNSçµŒç”±ã§ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥

---

## 7. å°†æ¥ã®æ‹¡å¼µ

### 7.1 æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®š

ç¾åœ¨ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®åˆ¤å®šã§ã™ãŒã€å°†æ¥çš„ã«ã¯ä»¥ä¸‹ã‚’æ¤œè¨ï¼š

- **ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«**: éå»ã®åˆæ ¼/ä¸åˆæ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å­¦ç¿’
- **è‡ªå‹•èª¿æ•´ææ¡ˆ**: å¤±æ•—ã—ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨è–¦

### 7.2 A/Bãƒ†ã‚¹ãƒˆçµ±åˆ

- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸¦è¡Œãƒ‡ãƒ—ãƒ­ã‚¤ã¨æ€§èƒ½æ¯”è¼ƒ
- ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ†å‰²ã«ã‚ˆã‚‹æ®µéšçš„è©•ä¾¡

---

## 8. ã¾ã¨ã‚

Judge Agentã¯ã€ä»¥ä¸‹ã®ç†ç”±ã§MCPåŒ–ã›ãšAWS Lambdaå˜ä½“ã§å®Ÿè£…ã—ã¾ã™ï¼š

1. **è»½é‡ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯**: è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚„MLè¨ˆç®—ã¯ä¸è¦
2. **ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¦æ±‚**: Step Functionsã¨ã®å¯†çµåˆã§é«˜é€Ÿå¿œç­”ãŒå¿…è¦
3. **AWSç‰¹åŒ–ã®æ©Ÿèƒ½**: Step Functionsã¨ã®çµ±åˆãŒãƒ¡ã‚¤ãƒ³ç”¨é€”

ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®ã‚·ãƒ³ãƒ—ãƒ«ã•ã¨ä¿å®ˆæ€§ã‚’ç¶­æŒã—ã¤ã¤ã€åŠ¹ç‡çš„ãªåˆ¤å®šãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
